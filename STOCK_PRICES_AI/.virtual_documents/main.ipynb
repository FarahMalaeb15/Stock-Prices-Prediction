


import pandas as pd


# Load datasets
df_1yr = pd.read_csv('all_stocks_1yr.csv')
df_5yr = pd.read_csv('all_stocks_5yr.csv')

# Display basic information
print(df_1yr.shape)
print(df_5yr.shape)



# Check for null values
# Display the non-null DataFrame
non_null_values_1yr = df_1yr.isnull().sum()
non_null_values_5yr = df_5yr.isnull().sum()
print(non_null_values_1yr)
print(non_null_values_5yr)


# Impute with median values
# For 1-year dataset
df_1yr['Open'] = df_1yr['Open'].fillna(df_1yr['Open'].median())
df_1yr['High'] = df_1yr['High'].fillna(df_1yr['High'].median())
df_1yr['Low'] = df_1yr['Low'].fillna(df_1yr['Low'].median())
df_1yr['Volume'] = df_1yr['Volume'].fillna(df_1yr['Volume'].median())



# For 5-year dataset
df_5yr['Open'] = df_5yr['Open'].fillna(df_5yr['Open'].median())
df_5yr['High'] = df_5yr['High'].fillna(df_5yr['High'].median())
df_5yr['Low'] = df_5yr['Low'].fillna(df_5yr['Low'].median())
df_5yr['Volume'] = df_5yr['Volume'].fillna(df_5yr['Volume'].median())



# Check for null values after filling
print(df_1yr.isnull().sum())
print(df_5yr.isnull().sum())



duplicates_1yr = df_1yr.duplicated()
duplicates_5yr = df_5yr.duplicated()
print(duplicates_1yr)
print(duplicates_5yr)


# Check for negative prices
invalid_prices_1yr = df_1yr[(df_1yr['Open'] < 0) | (df_1yr['High'] < 0) | (df_1yr['Low'] < 0) | (df_1yr['Close'] < 0)]
invalid_prices_5yr = df_5yr[(df_5yr['Open'] < 0) | (df_5yr['High'] < 0) | (df_5yr['Low'] < 0) | (df_5yr['Close'] < 0)]

# Check for invalid volumes
invalid_volumes_1yr = df_1yr[df_1yr['Volume'] <= 0]
invalid_volumes_5yr = df_5yr[df_5yr['Volume'] <= 0]

print(f"Invalid prices: {len(invalid_prices_1yr)}")
print(f"Invalid prices: {len(invalid_prices_5yr)}")

print(f"Invalid volumes: {len(invalid_volumes_1yr)}")
print(f"Invalid volumes: {len(invalid_volumes_5yr)}")


#Handling Invalid volumes
# Inspect rows with invalid volumes
invalid_volumes_rows_1yr = df_1yr[df_1yr['Volume'] <= 0]
invalid_volumes_rows_5yr = df_5yr[df_5yr['Volume'] <= 0]
print(invalid_volumes_rows_1yr)
print(invalid_volumes_rows_5yr)

# Drop rows where 'Volume' is 0
df_1yr = df_1yr[df_1yr['Volume'] > 0]
df_5yr = df_5yr[df_5yr['Volume'] > 0]

#using drop() with condition
df_1yr.drop(df_1yr[df_1yr['Volume'] == 0].index, inplace=True)
df_5yr.drop(df_5yr[df_5yr['Volume'] == 0].index, inplace=True)



# Verify the drop was successful
print(df_1yr['Volume'].isnull().sum())
print(df_5yr['Volume'].isnull().sum())


zero_volumes_1yr = df_1yr[df_1yr['Volume'] == 0]
zero_volumes_5yr = df_5yr[df_5yr['Volume'] == 0]
print(zero_volumes_1yr)
print(zero_volumes_5yr)


# Convert 'Date' column to datetime format
df_1yr['Date'] = pd.to_datetime(df_1yr['Date'], format='%Y-%m-%d', errors='coerce')
df_5yr['Date'] = pd.to_datetime(df_5yr['Date'], format='%Y-%m-%d', errors='coerce')

# Check the types after conversion
print(df_1yr['Date'].dtype)
print(df_5yr['Date'].dtype)



# If needed, convert back to string format 'YYYY-MM-DD'
df_1yr['Date'] = df_1yr['Date'].dt.strftime('%Y-%m-%d')
df_5yr['Date'] = df_5yr['Date'].dt.strftime('%Y-%m-%d')

# Verify the conversion
print(df_1yr['Date'].head())
print(df_5yr['Date'].head())


import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import SimpleRNN, Dense, Dropout, Input
from tensorflow.keras.optimizers import Adam


# Feature engineering for 1-year dataset (using 'Open', 'High', 'Low', 'Close', 'Volume' for prediction)
features_1yr = ['Open', 'High', 'Low', 'Close', 'Volume']
scaler_1yr = MinMaxScaler(feature_range=(0, 1))
df_1yr[features_1yr] = scaler_1yr.fit_transform(df_1yr[features_1yr])

# Feature engineering for 5-year dataset (using 'Open', 'High', 'Low', 'Close', 'Volume' for prediction)
features_5yr = ['Open', 'High', 'Low', 'Close', 'Volume']
scaler_5yr = MinMaxScaler(feature_range=(0, 1))
df_5yr[features_5yr] = scaler_5yr.fit_transform(df_5yr[features_5yr])




# Creating the 'Movement' target variable (1 for price increase, 0 for price decrease)
df_1yr['Movement'] = (df_1yr['Close'].shift(-1) > df_1yr['Close']).astype(int)
df_5yr['Movement'] = (df_5yr['Close'].shift(-1) > df_5yr['Close']).astype(int)



# Now, instead of predicting 'Close', we predict 'Movement'
y_1yr = df_1yr['Movement'].iloc[sequence_length:].values  # Start from index 60 to match the sequence length

# Prepare input sequences for 1-year dataset
x_1yr = np.array([df_1yr.iloc[i-sequence_length:i][features_1yr].values for i in range(sequence_length, len(df_1yr))])



# Now, instead of predicting 'Close', we predict 'Movement'
y_1yr = df_1yr['Movement'].iloc[sequence_length:].values  # Start from index 60 to match the sequence length

# Prepare input sequences for 1-year dataset
x_1yr = np.array([df_1yr.iloc[i-sequence_length:i][features_1yr].values for i in range(sequence_length, len(df_1yr))])



# Now, instead of predicting 'Close', we predict 'Movement'
y_5yr = df_5yr['Movement'].iloc[sequence_length:].values  # Same for 5-year data

# Prepare input sequences for 5-year dataset
x_5yr = np.array([df_5yr.iloc[i-sequence_length:i][features_5yr].values for i in range(sequence_length, len(df_5yr))])



# Split the 1-year data into training and testing sets (80% training, 20% testing)
x_train_1yr, x_test_1yr, y_train_1yr, y_test_1yr = train_test_split(x_1yr, y_1yr, test_size=0.2, random_state=42)



# Split the 5-year data into training and testing sets (80% training, 20% testing)
x_train_5yr, x_test_5yr, y_train_5yr, y_test_5yr = train_test_split(x_5yr, y_5yr, test_size=0.2, random_state=42)



from tensorflow.keras.layers import LSTM

# Define the model for 1-year dataset
model_1yr = Sequential()

# Add LSTM layers
model_1yr.add(LSTM(units=50, return_sequences=True, input_shape=(x_train_1yr.shape[1], x_train_1yr.shape[2])))
model_1yr.add(Dropout(0.2))

model_1yr.add(LSTM(units=50, return_sequences=False))
model_1yr.add(Dropout(0.2))

# Add a dense layer for the output (prediction)
model_1yr.add(Dense(units=1))  # Single value output for regression

# Compile the model
model_1yr.compile(optimizer='adam', loss='mean_squared_error')

# Summary of the model
model_1yr.summary()

# Now let's train the model
history_1yr = model_1yr.fit(x_train_1yr, y_train_1yr, epochs=20, batch_size=32, validation_data=(x_test_1yr, y_test_1yr))



# Define the model for 5-year dataset
model_5yr = Sequential()

# Add LSTM layers
model_5yr.add(LSTM(units=50, return_sequences=True, input_shape=(x_train_5yr.shape[1], x_train_5yr.shape[2])))
model_5yr.add(Dropout(0.2))

model_5yr.add(LSTM(units=50, return_sequences=False))
model_5yr.add(Dropout(0.2))

# Add a dense layer for the output (prediction)
model_5yr.add(Dense(units=1))  # Single value output for regression

# Compile the model
model_5yr.compile(optimizer='adam', loss='mean_squared_error')

# Summary of the model
model_5yr.summary()

# Now let's train the model
history_5yr = model_5yr.fit(x_train_5yr, y_train_5yr, epochs=20, batch_size=32, validation_data=(x_test_5yr, y_test_5yr))



# Evaluate the 1-year model
mse_1yr = model_1yr.evaluate(x_test_1yr, y_test_1yr)
print("Mean Squared Error for 1-year dataset:", mse_1yr)

# Evaluate the 5-year model
mse_5yr = model_5yr.evaluate(x_test_5yr, y_test_5yr)
print("Mean Squared Error for 5-year dataset:", mse_5yr)



import numpy as np

# Step 1: Generate random data for prediction (5 features: Open, High, Low, Close, Volume)
# Make sure the range of the random data matches the expected feature ranges
random_data_1yr = np.random.rand(1, 5)  # 1 sample, 5 features (Open, High, Low, Close, Volume)
random_data_5yr = np.random.rand(1, 5)  # Similar for 5-year dataset

# Step 2: Scale the random data using the same scaler used for training
scaled_random_data_1yr = scaler_1yr.transform(random_data_1yr)
scaled_random_data_5yr = scaler_5yr.transform(random_data_5yr)

# Step 3: Reshape the data to match the expected input shape for the model (3D shape for LSTM)
scaled_random_data_1yr = scaled_random_data_1yr.reshape(1, 1, 5)  # 1 sample, 1 timestep, 5 features
scaled_random_data_5yr = scaled_random_data_5yr.reshape(1, 1, 5)

# Step 4: Make predictions with the models
prediction_1yr = model_1yr.predict(scaled_random_data_1yr)
prediction_5yr = model_5yr.predict(scaled_random_data_5yr)

# Step 5: Output the predictions
print("1-Year Dataset Prediction:", prediction_1yr)
print("5-Year Dataset Prediction:", prediction_5yr)

